{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"If it does not work use code below while running this notebook in this dir.\"\n",
    "# import sys\n",
    "# import os\n",
    "# sys.path.append(os.path.abspath(os.getcwd()))\n",
    "\n",
    "from mytorch import Tensor, Model\n",
    "from mytorch import activation as active_func\n",
    "from mytorch import loss as loss_func\n",
    "from mytorch import optimizer as optim \n",
    "from mytorch import layer as nn\n",
    "from mytorch.util import DataLoader\n",
    "\n",
    "from mytorch.util import flatten\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "load data set with given data loader.\n",
    "you have 10000 train data, 1000 for each number, remember to shuffle training data.\n",
    "you have 1000 test data, 100 for each number.\n",
    "\n",
    "loaded data is a list of (img, label)\n",
    "type of img is Tensor.\n",
    "\n",
    "TODO: you have to get this list and create batches for training.\n",
    "you can also apply this changes later in the Training part for convenience.\n",
    "\"\"\"\n",
    "data_loader = DataLoader(train_addr='MNIST/train', test_addr='MNIST/test')\n",
    "data_loader.load()\n",
    "\"you can see how data is loaded\"\n",
    "print(data_loader.getTrain()[0][0].shape)\n",
    "print(data_loader.getTrain()[0][1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and Create your Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mytorch import activation\n",
    "\n",
    "class MyModel(Model):\n",
    "    def __init__(self):\n",
    "        self.fc1 = nn.Linear(784, 450, need_bias=True)\n",
    "        self.fc2 = nn.Linear(450, 250, need_bias=True)\n",
    "        self.fc3 = nn.Linear(250, 50, need_bias=True)\n",
    "        self.fc4 = nn.Linear(50, 10, need_bias=True)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"TODO: define forward pass\"\n",
    "        x = Tensor(x.data.reshape(-1, 28*28), requires_grad=x.requires_grad, depends_on=x.depends_on)\n",
    "        x = activation.relu(self.fc1(x))\n",
    "        x = activation.relu(self.fc2(x))\n",
    "        x = activation.leaky_relu(self.fc3(x), alpha=0.075)\n",
    "        x = activation.relu(self.fc4(x))\n",
    "        return activation.softmax(x)\n",
    "\n",
    "model = MyModel()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose a Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"TODO: choose a proper loss function\"\n",
    "criterion = loss_func.CategoricalCrossEntropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose an Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"TODO: choose a proper optimizer\"\n",
    "optimizer = optim.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"TODO: define number of epoch and train batches of data on your model. also test each epoch.\"\n",
    "EPOCH = 30\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    best_train_acc = 0.0\n",
    "    best_test_acc = 0.0\n",
    "\n",
    "    \"TODO: train over your defined batches and save train accuracy for each epoch.\"\n",
    "    \n",
    "    \"TODO: test your model after each training and save test accuracy for each epoch.\"\n",
    "    \n",
    "  \n",
    "    for images, labels in data_loader.getTrain():\n",
    "        outputs = model(images)\n",
    "\n",
    "        max_value = 9\n",
    "        one_hot_matrix = np.eye(10)\n",
    "        one_hot_encoded = one_hot_matrix[labels.data]\n",
    "        loss = loss_func.CategoricalCrossEntropy(outputs, Tensor(one_hot_encoded, requires_grad=labels.requires_grad, depends_on=labels.depends_on))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(grad=Tensor(0.0))\n",
    "        optimizer.step()\n",
    "\n",
    "        predicted = np.argmax(outputs, axis=1)\n",
    "        train_count = labels.size(0)\n",
    "        train_acc.append((predicted == labels).sum().item() / train_count)\n",
    "        \n",
    "        if train_acc[-1] > best_train_acc:\n",
    "            best_train_acc = train_acc[-1]\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{EPOCH}], Train Accuracy: {train_acc[-1]:.4f}')\n",
    "    \n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    \n",
    "    for images, labels in data_loader.getTest():\n",
    "        outputs = model(images)\n",
    "        predicted = np.argmax(outputs, axis=1)\n",
    "        total_test += labels.size(0)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "    test_accuracy = correct_test / total_test\n",
    "\n",
    "    if best_test_acc < test_accuracy:\n",
    "        best_test_acc = test_accuracy\n",
    "    \n",
    "    test_acc.append(test_accuracy)\n",
    "\n",
    "    print(f'Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_acc, label='train accuracy')\n",
    "plt.plot(test_acc, label = 'test accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show();\n",
    "\n",
    "print(\"\\nOn train - best accuracy: {:.2f}, final accuracy: {:.2f}\".format(best_train_acc, train_acc[-1]))\n",
    "print(\"On test - best accuracy: {:.2f}, final accuracy: {:.2f}\".format(best_test_acc, test_acc[-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
